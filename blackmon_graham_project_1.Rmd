---
title: "DS6372 - Applied Statistics - Project 1"
author: "Brittany Blackmon and Eric Graham"
date: "`r Sys.Date()`"
output:
  html_document:
    toc: true
    toc_depth: 3
    code_folding: hide
    theme: flatly
---

# Setup and Data Import

```{r setup, include=FALSE}
load_or_install = function(pkg) {
  if (!require(pkg, character.only = TRUE)) {
    install.packages(pkg, dependencies = TRUE)
    library(pkg, character.only = TRUE)
  }
}

packages = c(
  "tidyverse",
  "skimr",
  "naniar",
  "corrplot",
  "ggthemes",
  "caret",
  "knitr",
  "car",
  "lmboot",
  "glmnet",
  "randomForest"
)
invisible(lapply(packages, load_or_install))
```

```{r}
df = read.csv("HospitalDurations.csv", header = TRUE)
names(df)
```

# Exploratory Data Analysis

## Variable Classification and Basic Cleaning

Our response variable is Length of Stay. For Analysis 1, we're performing an inferential analysis on the relationship between infection risk and length of stay, but we will also explore the relationships between length of stay and other predictors. 

For Analysis 2, we will build two predictive models: one complex MLR and one random forest model.

We don't need to perform any analysis on the ID variable, so we dropped it from the dataframe.

Because Medical School Affiliation and Region are categorical variables, we will convert them to factors and clearly relabel them.

The remainder of our predictors are numeric, and we'll further identify which are continuous and which are discrete later in the analysis.

```{r}
response_var = "Lgth.of.Sty"

df = df %>% select(-ID)

df$Med.Sc.Aff <- factor(df$Med.Sc.Aff, levels = c(1, 2), labels = c("Yes", "No"))
df$Region <- factor(df$Region, levels = c(1, 2, 3, 4), labels = c("NE", "NC", "S", "W"))

cat_vars = df %>% select(where(is.factor)) %>% names()
num_vars = df %>% select(where(is.numeric)) %>% names()

num_vars = setdiff(num_vars, response_var)

# cat_vars
# num_vars
```

```{r}
head(df)
glimpse(df)
skim(df)
```

Using the glimpse() and skim() functions, we can see that data has been gathered from 113 hospitals. This is a relatively small number, which will need to be addressed in modeling. 

The data types are appropriate for our analysis. The categorical variables are factors, and the numeric variables are either integers or doubles.

Our skim() of the data above showed that there are no missing values, so removal of incomplete records or imputation of missing variables won't be necessary.

## Variable Glossary Table

```{r}
data.frame(
  Variable_Name = c(
    "Hospital ID", "Length of Stay", "Age", "Infection risk", 
    "Routine culturing ratio", "Routine chest X-ray ratio",
    "Number of beds", "Medical School Affiliation", "Region", 
    "Average Daily census", "Number of nurses", "Available facilities"
  ),
  Description = c(
    "Unique identifier for the hospital", 
    "Average length of stay (in days)",
    "Average age of patients (years)",
    "Estimated probability of hospital infection (%)",
    "(# of cultures / # of asymptomatic patients) × 100",
    "(# of chest X-rays / # of asymptomatic patients) × 100",
    "Average number of beds",
    "Whether the hospital is affiliated with a medical school (Yes or No)",
    "Geographic region (NE, NC, S, or W)",
    "Average number of patients in hospital per day",
    "Average number of full-time nurses",
    "Percent of 35 possible facilities and services provided"
  ),
  `Data Type` = c("character", "double", "double", "double", "double", "double", "integer", "factor", "factor", "integer", "integer", "double"),
  Type = c("categorical", "continuous", "continuous", "continuous", "continuous", "continuous", "discrete", "categorical", "categorical", "continuous", "continuous", "continuous")
) |>
  kable()
```

## Univariate Analysis

### Discrete vs. Continuous Classification

Though the number of beds in a hospital is a discrete variable, the distribution of values in this dataset is so wide that bar plots wouldn't be interpretable. We have chosen to treat it as continuous for the purposes of our analysis.

```{r}
# dictionary of feature names and labels
label_dict <- c(
  "ID"             = "Hospital ID",
  "Lgth.of.Sty"    = "Length of Stay (days)",
  "Age"            = "Average Age (years)",
  "Inf.Risk"       = "Infection Risk",
  "R.Cul.Rat"      = "Routine Culturing Ratio (%)",
  "R.CX.ray.Rat"   = "Routine Chest X-ray Ratio (%)",
  "N.Beds"         = "Number of Beds",
  "Med.Sc.Aff"     = "Medical School Affiliation",
  "Region"         = "Region",
  "Avg.Pat"        = "Average Daily Census",
  "Avg.Nur"        = "Number of Nurses",
  "Pct.Ser.Fac"    = "Available Facilities (%)"
)
# helper function to strip underscores and convert to title case
pretty_var = function(x) {
  gsub("_", " ", tools::toTitleCase(x))
}
# helper function to get labels from dictionary
get_label <- function(varname) {
  if (varname %in% names(label_dict)) {
    return(label_dict[[varname]])
  } else {
    return(pretty_var(varname))
  }
}

```

### Distribution of Response Variable

```{r}
p = ggplot(df, aes(x = Lgth.of.Sty)) +
  geom_histogram(fill = "steelblue", color = "white") +
  labs(
    x = "Length of Stay",
    title = "Distribution of Length of Stay"
  ) +
  theme_minimal()
  
print(p)

p = ggplot(df, aes(y = Lgth.of.Sty)) +
  geom_boxplot(fill = "steelblue") +
  coord_flip() +
  labs(y = "Length of Stay", title = "Boxplot of Length of Stay") +
  theme_minimal()
  
print(p)
```

The distribution of lengths of stay is mostly normal, with two notable outliers. If there are issues with fit diagnostics then we might consider a transformation, but given the shape of our response variable it seems more likely that we would look to transformations on predictors.

### Numeric Predictors

<details>
<summary>Click to expand: Numeric Variable Plots</summary>

```{r}
for (var in num_vars) {
  p <- ggplot(df, aes(x = !!sym(var))) +
    geom_histogram(fill = "steelblue", color = "white") +
    labs(
      x = get_label(var),
      title = paste("Distribution of", get_label(var))
    ) +
    theme_minimal()
  
  print(p)
}
```

```{r}
for (var in num_vars) {
  p = ggplot(df, aes(y = !!sym(var))) +
    geom_boxplot(fill = "steelblue") +
    coord_flip() +
    labs(y = get_label(var), title = paste("Boxplot of", get_label(var))) +
    theme_minimal()
  print(p)
}
```


</details>

We see that most of our numeric predictors are normally distributed, but the routine culturing ratio, number of beds, average daily census, and number of nurses are right-skewed. Our primary predictor of interest is infection risk, which is relatively normally distributed. If we run into issues with model performance or residual diagnostics, we may implement log transformations of the right-skewed predictors.

### Categorical Variables

<details>
<summary>Click to expand: Categorical Variable Plots</summary>

```{r}
for (var in cat_vars) {
  p = ggplot(df, aes(x = !!sym(var))) +
    geom_bar(fill = "steelblue") +
    labs(
      x = get_label(var),
      y = "Count",
      title = paste("Frequency of", get_label(var))
    ) +
    theme_minimal()
  
  print(p)
}

```

</details>

We note that medical school affiliation is imbalanced: the majority of schools don't have a medical school affiliation. This may impact its usefulness in a train/test split for the predictive model, so we will need to keep an eye on that.  

### Outlier Analysis

```{r}
outlier_summary = data.frame()

for (var in num_vars) {
  values = df[[var]]
  q1 = quantile(values, 0.25, na.rm = TRUE)
  q3 = quantile(values, 0.75, na.rm = TRUE)
  iqr = q3 - q1
  lower = q1 - 1.5 * iqr
  upper = q3 + 1.5 * iqr
  outliers = sum(values < lower | values > upper, na.rm = TRUE)
  pct = 100 * outliers / sum(!is.na(values))
  outlier_summary = rbind(
    outlier_summary,
    data.frame(variable = var, num_outliers = outliers, pct_outliers = round(pct, 1))
  )
}

outlier_summary
```

We see some outliers in our predictors, but none of them are extreme enough to warrant removal. We will be keeping an eye out for high-leverage points in our model fit diagnostics.

## Bivariate / Multivariate Analysis

### Infection Rate vs. Numeric Predictors

```{r}
for (var in num_vars) {
  p = ggplot(df, aes(x = !!sym(var), y = Lgth.of.Sty)) +
    geom_point(alpha = 0.6, color = "steelblue") +
    geom_smooth(method = "loess", se = TRUE, color = "darkred", linetype = "solid") +
    labs(
      x = get_label(var),
      y = "Length of Stay",
      title = paste("Length of Stay vs", get_label(var))
    ) +
    theme_minimal()
  
  print(p)
}

```

A visual examination of the relationships between our numeric predictors and length of stay shows that there is a moderate, positive linear relationship between infection risk and length of stay, which is the most important relationship we will be exploring in our inferential model.

Average age has a weak positive linear relationship.

Routine culturing ratio has a slight rise in the 15%-20% range, then flattens. 

Routine chest x-ray ratio, number of beds, average daily census, number of nurses, and available facilities percentage are mostly flat and then rise: in the case of average daily census, the lift at the right end of the line is quite dramatic. 

The overall trend for these predictors is positive, but it's difficult to call the relationships linear, and the shapes of the distributions are such that a simple log or polynomial transformation may not be sufficient to perfectly capture the relationships. 

Though some relationships are more linear than others, we will proceed with the assumption that they are all linear for the purposes of our inferential model.

### Infection Rate vs. Categorical Predictors

```{r}
for (var in cat_vars) {
  p = ggplot(df, aes(x = !!sym(var), y = Lgth.of.Sty)) +
    geom_boxplot(fill = "steelblue", color = "darkblue", outlier.shape = NA, alpha = 0.7) +
    geom_jitter(width = 0.2, alpha = 0.4, color = "black") +
    labs(
      x = get_label(var),
      y = "Length of Stay",
      title = paste("Length of Stay by", get_label(var))
    ) +
    theme_minimal()
  
  print(p)
}
```

A visual examination of the relationships between our categorical predictors and length of stay shows that the mean length of stay is generally higher among hospitals with a medical school affiliation, while region definitely appears to have an effect on length of stay, with the Northeast and North Central regions having the highest mean lengths of stay.


# Inferential Model

## Baseline Inferential Model

```{r}
fit1 = lm(Lgth.of.Sty ~  Inf.Risk + Age + R.Cul.Rat + R.CX.ray.Rat + N.Beds + Med.Sc.Aff + Region + Avg.Pat + Avg.Nur + Pct.Ser.Fac, data = df)
par(mfrow = c(2, 2))
plot(fit1)
summary(fit1)
vif(fit1)
```

Our initial fit of the inferential model using all variables shows that infection risk is likely a strong predictor of length of stay, and we will continue to explore that relationship in-depth throughout our analysis. 

Our adjusted-r-squared value of 0.5855 indicates that the model explains about 59% of the variance in length of stay, which is a decent starting point for a first pass at the model.

Our VIF check shows that the number of beds and average number of patients are highly correlated, which intuitively makes sense: both are measures of hospital capacity. Because we see that the average number of patients is a stronger predictor of length of stay, we will drop the number of beds from our model.

We see that infection risk, age, region, average patients, and average nurses are all statistically significant in the model. We will keep these variables in our second, reduced model.

### Fit Diagnostics

We see a slight curve in the residuals vs. fitted values plot, which suggests that the relationship between infection risk and length of stay may not be perfectly linear, but nothing to suggest a major violation of linearity.

The QQ plot shows some deviation at the tails, but (again) nothing to suggest a major violation of normality.

We see a couple of outliers here, but nothing outside the Cook's D threshold of 0.5.

Overall, the fit diagnostics could be better, but they are acceptable for a first pass at the model.

## Reduced Model

```{r}
fit2 = lm(Lgth.of.Sty ~ Inf.Risk + Age + Region + Avg.Pat + Avg.Nur + R.CX.ray.Rat, data = df)
# par(mfrow = c(2, 2))
plot(fit2)
summary(fit2)
vif(fit2)
```

We dropped number of beds (as noted above) as well as medical school affiliation, percent of available facilities, and routine culturing ratio, which were not statistically significant in the baseline model. This resulted in an adjusted r-squared of .5846, which is roughly the same as we had before.

We also tried dropping routine chest x-ray ratio, which was closer to the threshold of statistical signficance than the other dropped predictors (p-value of 0.08). However, removing it from the model actually lowered our adjusted r-squared value, and in the reduced model its p-value was borderline (0.057, as shown below), so we left it in. 

Fit diagnostics are marginally improved in the reduced model, but not noticeably so. Overall, the reduced model enhances interpretability by dropping statistically insignificant predictors, but it does not significantly improve the model fit.

## Model with Interactions

For the sake of simplicity in the inferential model, we limited our exploration of interactions to a few key variables, with a focus on infection risk since it is the subject of our inquiry and it seems to have the strongest linear relationship with length of stay. It seems intuitive that infection risk might interact with region, age, and average number of patients, so we examined the graphs of those interactions.

```{r}
ggplot(df, aes(x = Inf.Risk, y = Lgth.of.Sty, shape = Region)) +
  geom_point(alpha = 0.6) +
  geom_smooth(method = "lm", se = FALSE, aes(group = Region)) +
  labs(title = "Interaction Between Infection Risk and Region",
       x = "Infection Risk",
       y = "Length of Stay")

df$AgeGroup = cut(df$Age, breaks = 3, labels = c("Young", "Middle", "Old"))

ggplot(df, aes(x = Inf.Risk, y = Lgth.of.Sty, shape = AgeGroup)) +
  geom_point(alpha = 0.6) +
  geom_smooth(method = "lm", se = FALSE, aes(group = AgeGroup)) +
  labs(title = "Interaction Between Infection Risk and Age Group",
       x = "Infection Risk",
       y = "Length of Stay")

df$PatGroup = cut(df$Avg.Pat, breaks = 3, labels = c("Low", "Medium", "High"))

ggplot(df, aes(x = Inf.Risk, y = Lgth.of.Sty, shape = PatGroup)) +
  geom_point(alpha = 0.6) +
  geom_smooth(method = "lm", se = FALSE, aes(group = PatGroup)) +
  labs(title = "Interaction Between Infection Risk and Average Patients",
       x = "Infection Risk",
       y = "Length of Stay")
```

We see that infection risk has a stronger effect on length of stay in the Northeast and South regions, and that it has a stronger effect in hospitals with higher average daily census. The influence of age on the relationship between infection risk and length of stay is less pronounced. 

Thus, we refit the model to incorporate interactions for Region/Infection Risk and Average Patients/Infection Risk.

```{r}
fit3 = lm(Lgth.of.Sty ~ Inf.Risk + Age + Region + Avg.Pat + Avg.Nur + R.CX.ray.Rat + Inf.Risk*Region + Inf.Risk*Avg.Pat, data = df)
par(mfrow = c(2, 2))
plot(fit3)
summary(fit3)
vif(fit3, type = "predictor")
```

The introduction of the interaction terms improved our adjusted R-squared value to .6309, and the VIF values are still acceptable. 

The interaction terms for infection risk and region are significant in the NC and S regions, indicating that the relationship between infection risk and length of stay is stronger in those regions, as is the interaction term for infection risk and average patients, indicating that the relationship between infection risk and length of stay is stronger in hospitals with higher average daily census.

Fit diagnostics remain consistent with the baseline model, which are acceptable but not perfect. Our last attempt to tame the residuals and improve the fit of the inferential model will be to apply log transformations to some of our predictors.

## Log Transformations on Average Daily Census and Number of Nurses

As seen in the univariate analysis, the distributions of both average number of patients and number of nurses are highly skewed, and the relationships between these predictors and length of stay are not perfectly linear. 

```{r}
log_Avg.Pat = log(df$Avg.Pat)
log_Avg.Nur = log(df$Avg.Nur)
df = df %>% mutate(log_Avg.Pat = log_Avg.Pat, log_Avg.Nur = log_Avg.Nur)

ggplot(df, aes(x = log_Avg.Pat)) +
  geom_histogram(fill = "steelblue", color = "white") +
  labs(
    x = "Log of Average Daily Census",
    title = "Distribution of Log of Average Daily Census"
  ) +
  theme_minimal()

ggplot(df, aes(x = log_Avg.Nur)) +
  geom_histogram(fill = "steelblue", color = "white") +
  labs(
    x = "Log of Number of Nurses",
    title = "Distribution of Log of Number of Nurses"
  ) +
  theme_minimal()

ggplot(df, aes(x = log_Avg.Pat, y = Lgth.of.Sty)) +
  geom_point(alpha = 0.6, color = "steelblue") +
  geom_smooth(method = "loess", se = TRUE, color = "darkred", linetype = "solid") +
  labs(
    x = paste("Log of Average Patients"),
    y = "Length of Stay",
    title = paste("Length of Stay vs Log of Average Patients")
  ) +
  theme_minimal()

ggplot(df, aes(x = log_Avg.Nur, y = Lgth.of.Sty)) +
  geom_point(alpha = 0.6, color = "steelblue") +
  geom_smooth(method = "loess", se = TRUE, color = "darkred", linetype = "solid") +
  labs(
    x = paste("Log of Average Nurses"),
    y = "Length of Stay",
    title = paste("Length of Stay vs Log of Average Nurses")
  ) +
  theme_minimal()
```

The distributions of the log-transformed variables certainly can't be considered skewed! However, their relationships to the response variable are still barely linear. They aren't that much less linear than our other non-infection risk predictors, so we will at least try with the log-transformed variables in our inferential model.

```{r}
fit4 = lm(Lgth.of.Sty ~ Inf.Risk + Age + Region + log_Avg.Pat + log_Avg.Nur + R.CX.ray.Rat + Inf.Risk*Region + Inf.Risk*log_Avg.Pat, data = df)
# par(mfrow = c(2, 2))
plot(fit4)
summary(fit4)
vif(fit4)
```

The introduction of the log-transformed variables improved our adjusted R-squared value to .6171, which is a slight improvement over the previous model. However, the fit diagnostics (particularly the residuals vs. fitted values plot and QQ plot) show that the log transformations did not significantly improve the linearity of the relationships between the predictors and the response variable. 

## Final Inferential Model 

Given the choice between the reduced model with interactions and the log-transformed model, we will proceed with the reduced model with interactions as our final inferential model. The log transformations did not significantly improve the fit of the model and had worse residual diagnostics. The reduced model with interactions has a higher adjusted R-squared value.

```{r}
final_inferential_mlr = lm(Lgth.of.Sty ~ Inf.Risk + Age + Region + Avg.Pat + Avg.Nur + R.CX.ray.Rat + Inf.Risk*Region + Inf.Risk*Avg.Pat, data = df)
par(mfrow = c(2, 2))
plot(final_inferential_mlr)
summary(final_inferential_mlr)
```


## Bootstrap Confidence Interval for Infection Risk Coefficient

Since the specific question of interest is the relationship between infection risk and length of stay, we want to provide a robust confidence interval for the infection risk coefficient. Given the small sample size of 113 hospitals, we will use a bootstrap approach to estimate the confidence interval.

```{r}
boot.p = paired.boot(Lgth.of.Sty ~ Inf.Risk + Age + Region + Avg.Pat + Avg.Nur + R.CX.ray.Rat + Inf.Risk*Region + Inf.Risk*Avg.Pat, data = df, B = 10000, seed = 1234)
ci = t(apply(boot.p$bootEstParam, 2, quantile, probs = c(0.025, 0.975)))
print(ci)
```

Based on the bootstrap confidence interval, we are 95% coonfident that for each 1-unit increase in Infection Risk, the mean Length of Stay increases by somewhere between 0.13 and 1.42 days, holding other factors constant.

# Predictive Model 1: Complex MLR

## Stepwise Feature Selection

We are very pleased with the results of our inferential model, which prioritizes interpretability and provides a robust confidence interval for the infection risk coefficient. Because our predictive MLR has different goals, we will use different tools for feature selection, starting with a stepwise feature selection approach.

```{r}
empty_model = lm(Lgth.of.Sty ~ 1, data = df)
full_model = lm(Lgth.of.Sty ~  (Inf.Risk + Age + R.Cul.Rat + R.CX.ray.Rat + N.Beds + Med.Sc.Aff + Region + Avg.Pat + Avg.Nur + Pct.Ser.Fac)^2, data = df)
stepwise_model = step(empty_model, scope = list(lower = empty_model, upper = full_model), direction = "both", trace = 0)
summary(stepwise_model)
vif(stepwise_model, type = "predictor")
```


## Using Lasso Regression to Select Interactions

```{r}
X = model.matrix(Lgth.of.Sty ~  (Inf.Risk + Age + R.Cul.Rat + R.CX.ray.Rat + N.Beds + Med.Sc.Aff + Region + Avg.Pat + Avg.Nur + Pct.Ser.Fac)^2, data = df)[ , -1]

y = df$Lgth.of.Sty

set.seed(1234)
lasso_cv = cv.glmnet(X, y, alpha = 1, family = "gaussian")
beta = as.matrix(coef(lasso_cv, s = "lambda.1se"))[-1 , , drop = FALSE]  
keep = beta[beta != 0 , , drop = FALSE]

selected = data.frame(term = rownames(keep), coef = as.vector(keep))
selected[order(abs(selected$coef), decreasing = TRUE), ]
```


```{r}
set.seed(1234)

control = trainControl(method = "repeatedcv", number = 10, repeats = 5, savePredictions = "final")

final_predictive_mlr = train(Lgth.of.Sty ~ Inf.Risk + Region + Avg.Pat + Avg.Nur + R.CX.ray.Rat + Age + Med.Sc.Aff + N.Beds + Inf.Risk:Avg.Pat + Inf.Risk:Region + Inf.Risk:Avg.Nur + Inf.Risk:R.CX.ray.Rat + Inf.Risk:Age + Med.Sc.Aff:Region + N.Beds:Region, data = df, method = "lm", trControl = control)
summary(final_predictive_mlr)
final_predictive_mlr$results
```


# Predictive Model 2: Random Forest

```{r}
set.seed(1234)

grid = expand.grid(mtry = 1:10)

control2 = trainControl(method = "repeatedcv", number = 10, repeats = 5)

fit6 = train(Lgth.of.Sty ~ ., data = df, method = "rf", trControl = control2, tuneGrid = grid, importance = TRUE)
fit6$results
ggplot(fit6$results, aes(x = mtry, y = RMSE)) +
  geom_line(color = "blue", size = 1) +
  geom_point(color = "red", size = 2) +
  labs(title = "Random Forest Tuning: RMSE vs. mtry",
       x = "Number of Variables Tried at Each Split (mtry)",
       y = "Root Mean Squared Error (RMSE)") +
  theme_minimal()
```

```{r}
final_forest = train(Lgth.of.Sty ~ ., data = df, method = "rf", trControl = control2, tuneGrid = expand.grid(mtry = 3), importance = TRUE)
final_forest$results
```

# Model Comparison

| Metric             | Explanatory MLR     | Predictive MLR  | Random Forest (`mtry = 3`) |
| ------------------ | ------------------- | --------------- | -------------------------- |
| Adjusted R²        | 0.631               | 0.639           | *NA (CV R² shown below)*   |
| Cross-Validated R² | *Not reported*      | 0.528           | 0.496                      |
| RMSE (CV)          | *Not reported*      | 1.366           | **1.347** (lowest)         |
| Model Complexity   | Moderate (12 terms) | High (23 terms) | High (hundreds of trees)   |
| Interpretability   | **High**            | Moderate        | **Low**                    |



